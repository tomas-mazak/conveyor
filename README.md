Log conveyor
============

This is a PoC repo.

Problem
-------

When running applications in Kubernetes, it is highly recommended that the apps print the log 
messages to the standard output and let Kubernetes handle the rest: https://12factor.net/logs

However, there are applications out there, that can only log into files on the local filesystem
and this logic is so hard-coded, it's difficult to change. These apps can rotate their logs,
but rely on other processes (cron, ...) to compress/archive/delete the rotated files.

In kubernetes:
  - We don't want to be running cron
  - We can't affort to ship logs periodically as containers can be deleted 
    and rescheduled at any time -- streaming solution must be used
  - We need to delete the rotated files not to fill up the space
  - When we multiplex all the log streams in stdout, we need to be able to distinguish between them
    to separate them again on the log storage

Solution
--------

Every Kubernetes pod can consist of multiple colocated containers, sharing some namespaces 
(network, IPC, ...). Typical architecture is to have one "main" container of the pod and set of
"sidecars", running supporting tools.

It should be possible to run a sidecar container, that will share a local volume with the main 
container. If all log files generated by the application can be directed into this volume and if
the "active" logs follow certain pattern, so they can be distinguished from the rotated files,
this sidecar will be able to read all the logs and dump them to the standard output, to mimic the
recommended behaviour.

Conveyor is a proof-of-concept app written in golang to do this.

### Conveyor idea

Upon start, conveyor reads the log dir (should be the volume shared with the "main" container):
  - it starts watching every file that matches the "active" log pattern
  - it deletes every file that doesn't match the pattern (it might be a leftover rotated file)

After that, the conveyor starts watching the directory using Inotify:
  - it starts watching every new file (CREATE, MOVED_TO) that matches the pattern
  - it deletes every new file that doesn't match the pattern (rotated files)

For every watched file:
  - read it from the beginning line-by-line, sending every line to the output, 
    prefixed with log filename
  - when EOF is reached, wait for inotify event:
      - if it was MODIFY, file was (hopefully) appended, continue reading
      - if it was DELETE_SELF or MOVED_SELF, file was (hopefully) rotated, close the file and
        stop watching
